{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Session 8 - Stable Diffusion\n",
        "## Text-to-Image Generation with Diffusion Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Learning Objectives:\n",
        "- Understand Stable Diffusion architecture\n",
        "- Generate images from text prompts\n",
        "- Experiment with parameters\n",
        "- Apply prompting best practices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q diffusers transformers torch accelerate scipy ftfy pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Load Stable Diffusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\nfrom diffusers import StableDiffusionPipeline\nimport matplotlib.pyplot as plt\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nmodel_id = 'runwayml/stable-diffusion-v1-5'\npipe = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16)\npipe = pipe.to(device)\nprint(f'\u2713 Model loaded on {device}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Architecture Inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('=== TEXT ENCODER (CLIP) ===')\nprint(f'Model: {pipe.text_encoder.__class__.__name__}')\nprint(f'Parameters: {sum(p.numel() for p in pipe.text_encoder.parameters()):,}')\nprint()\nprint('=== UNET DENOISER ===')\nprint(f'Parameters: {sum(p.numel() for p in pipe.unet.parameters()):,}')\nprint()\nprint('=== VAE ===')\nprint(f'Parameters: {sum(p.numel() for p in pipe.vae.parameters()):,}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Basic Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompt = 'a beautiful sunset over mountains, oil painting, 4k'\ngenerator = torch.Generator(device=device).manual_seed(42)\nimage = pipe(prompt, num_inference_steps=50, guidance_scale=7.5, generator=generator).images[0]\nprint('\u2713 Image generated successfully!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Prompt Complexity Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prompts = [\n    'a cat',\n    'a fluffy cat sitting',\n    'a majestic orange cat with striking eyes, sitting on antique chair',\n    'a professional portrait of orange tabby cat, highly detailed, 4k, oil painting'\n]\nfor idx, p in enumerate(prompts, 1):\n    print(f'{idx}. {p[:50]}...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Key Parameters\n\n| Parameter | Range | Sweet Spot | Effect |\n|-----------|-------|-----------|--------|\n| guidance_scale | 3-12 | 7-8 | Prompt adherence |\n| num_inference_steps | 10-100 | 40-50 | Quality/speed |\n| seed | 0-2^32 | Any | Reproducibility |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Conclusions\n\n\u2713 Detailed prompts produce better results\n\u2713 Guidance scale 7-8 is optimal\n\u2713 40-50 steps balances quality and speed\n\u2713 Seeds enable reproducibility"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}